{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5072607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위스콘신 유방암 데이터셋을 이용해서 logistict regression을 구현\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0750376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# 경고메시지 출력하지 않아요!\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ed04633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model의 정확도 : 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# raw data loading\n",
    "cancer = load_breast_cancer()\n",
    "x_data = cancer.data # 2차원 ndarray - 독립변수, feature\n",
    "t_data = cancer.target  # 1차원 ndarray - 종속변수, label\n",
    "\n",
    "train_x_data,test_x_data,train_t_data,test_t_data=train_test_split(x_data,t_data, test_size=0.3,stratify=t_data,random_state=2)\n",
    "#stratify = bias를 없애기 위해 t_data의 비율로 뽑으라는 얘기\n",
    "\n",
    "#model 생성\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "#model 학습\n",
    "model.fit(train_x_data,train_t_data)\n",
    "\n",
    "# accuracy로 model 평가\n",
    "test_score = model.score(test_x_data,test_t_data)\n",
    "\n",
    "print('Logistic Regression Model의 정확도 : {}'.format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2a9716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier Model의 정확도 : 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "# SDG분류\n",
    "# model 생성\n",
    "sgd = linear_model.SGDClassifier(loss='log',   # logistic regression을 이용\n",
    "                                tol=1e-5,      # 얼마나 반복할지를 loss 값으로 설정  \n",
    "                                random_state=2) \n",
    "\n",
    "# model 학습\n",
    "sgd.fit(train_x_data,train_t_data)\n",
    "\n",
    "# accuracy로 model 평가\n",
    "test_score = sgd.score(test_x_data,test_t_data)\n",
    "\n",
    "print('SGD Classifier Model의 정확도 : {}'.format(test_score))\n",
    "# 왜 정확도가 낮을까? => 정규화를 안함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e1386c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(x_data)\n",
    "# 각 feature 마다 값의 scale이 다름 -> 정규화를 해야함 \n",
    "# logistic은 내부적으로 정규화를 하지만 SGD는 안함\n",
    "# 우리가 해야됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7146492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화를 이용한 SGD Classifier Model의 정확도 : 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x_data)\n",
    "\n",
    "# model 생성\n",
    "sgd = linear_model.SGDClassifier(loss='log',   # logistic regression을 이용\n",
    "                                tol=1e-5,      # 얼마나 반복할지를 loss 값으로 설정  \n",
    "                                random_state=2) \n",
    "\n",
    "# model 학습\n",
    "sgd.fit(scaler.transform(train_x_data),train_t_data)\n",
    "\n",
    "# accuracy로 model 평가\n",
    "test_score = sgd.score(scaler.transform(test_x_data),test_t_data)\n",
    "\n",
    "print('정규화를 이용한 SGD Classifier Model의 정확도 : {}'.format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53f392fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화, 규제 SGD Classifier Model의 정확도 : 0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "# 위에다가 L2 regularization(규제)를 포함\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x_data)\n",
    "\n",
    "# model 생성\n",
    "sgd = linear_model.SGDClassifier(loss='log',   # logistic regression을 이용\n",
    "                                tol=1e-5,      # 얼마나 반복할지를 loss 값으로 설정  \n",
    "                                penalty='l2',  # L2 규제를 이용\n",
    "                                alpha=0.001,   # alpha가 커지면 규제가 강해짐 -> W값은 작아지고, 그래프가 평평해짐\n",
    "                                random_state=2) \n",
    "\n",
    "# model 학습\n",
    "sgd.fit(scaler.transform(train_x_data),train_t_data)\n",
    "\n",
    "# accuracy로 model 평가\n",
    "test_score = sgd.score(scaler.transform(test_x_data),test_t_data)\n",
    "\n",
    "print('정규화, 규제 SGD Classifier Model의 정확도 : {}'.format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dec8cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0adec86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  height  weight\n",
       "0          1     188      71\n",
       "1          2     161      68\n",
       "2          0     178      52\n",
       "3          2     136      63\n",
       "4          1     145      52\n",
       "...      ...     ...     ...\n",
       "19995      0     163      48\n",
       "19996      2     139      70\n",
       "19997      1     150      48\n",
       "19998      1     189      69\n",
       "19999      1     142      41\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BMI 데이터셋으로 multinomial 구현\n",
    "df = pd.read_csv('C:/jupyter_home/data/bmi.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed551284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "# 결측치 체크 \n",
    "# print(df.isnull().sum())   # 결측값 없음\n",
    "\n",
    "# 이상치 체크\n",
    "## z-score 방식으로 알아봄\n",
    "zscore_threshold = 2.0\n",
    "\n",
    "# (np.abs(stats.zscore(df['height']))>zscore_threshold).sum()  \n",
    "# (np.abs(stats.zscore(df['weight']))>zscore_threshold).sum()\n",
    "# np.unique(df['label'],return_counts=True)\n",
    "# 이상치도 없고 데이터의 편향도 존재하지 않음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3846f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화\n",
    "# 먼저 train과 test data를 분리한 후 정규화\n",
    "train_x_data,test_x_data,train_t_data,test_t_data=train_test_split(df[['height','weight']],\n",
    "                                                                  df['label'],\n",
    "                                                                  test_size=0.3,\n",
    "                                                                  random_state=1,\n",
    "                                                                  stratify=df['label'])\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_x_data)\n",
    "\n",
    "norm_train_x_data = scaler.transform(train_x_data)\n",
    "norm_test_x_data = scaler.transform(test_x_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41806d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn으로 구한 Accuracy : 0.9851666666666666\n"
     ]
    }
   ],
   "source": [
    "# model 생성 후 학습 및 평가\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "model.fit(norm_train_x_data, train_t_data)\n",
    "\n",
    "# 평가를 위한 예측결과를 얻어냄\n",
    "predict_val = model.predict(norm_test_x_data)\n",
    "# 예측결과를 test_t_data와 비교\n",
    "accuracy = accuracy_score(predict_val, test_t_data)\n",
    "\n",
    "print('sklearn으로 구한 Accuracy : {}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2225fea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# prediction \n",
    "result = model.predict(scaler.transform(np.array([[158,63]])))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffb37390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn으로 구한 Accuracy : 0.9843333333333333\n"
     ]
    }
   ],
   "source": [
    "# model 생성 후 학습 및 평가\n",
    "model = linear_model.LogisticRegression(C=10)\n",
    "# 규제를 적용(L2 규제)\n",
    "# alpha는 우리가 정해야함\n",
    "# C = 1/alpha\n",
    "\n",
    "model.fit(norm_train_x_data, train_t_data)\n",
    "\n",
    "# 평가를 위한 예측결과를 얻어냄\n",
    "predict_val = model.predict(norm_test_x_data)\n",
    "# 예측결과를 test_t_data와 비교\n",
    "accuracy = accuracy_score(predict_val, test_t_data)\n",
    "\n",
    "print('규제+sklearn으로 구한 Accuracy : {}'.format(accuracy))\n",
    "\n",
    "# overfitting이 크게 발생하지 않아서 규제에 따라 값이 크게 변화가 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "196f6cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "071354b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 51\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# tensorflow 사용해서 구현하기\n",
    "\n",
    "# multinomial 문제이기 때문에 label을 one-hot처리 해야함!\n",
    "# train_t_data, test_t_data를 one-hot encoding으로 변경할거임\n",
    "# tensorflow의 기능을 이용해서 변경 => tensorflow node로 생성\n",
    "sess = tf.Session()\n",
    "onehot_train_t_data=sess.run(tf.one_hot(train_t_data, depth=3))  # depth => 클래스 개수\n",
    "print(onehot_train_t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e498d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157      2\n",
       "12403    2\n",
       "4943     2\n",
       "8256     2\n",
       "15683    2\n",
       "        ..\n",
       "12005    2\n",
       "14672    1\n",
       "1856     2\n",
       "19291    0\n",
       "5494     0\n",
       "Name: label, Length: 14000, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9caf6c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value : 1.7567851543426514\n",
      "loss value : 0.511732816696167\n",
      "loss value : 0.41248297691345215\n",
      "loss value : 0.36121246218681335\n",
      "loss value : 0.3277733623981476\n",
      "loss value : 0.3035450875759125\n",
      "loss value : 0.28486180305480957\n",
      "loss value : 0.26984232664108276\n",
      "loss value : 0.2574019134044647\n",
      "loss value : 0.24686269462108612\n"
     ]
    }
   ],
   "source": [
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2],dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,3],dtype=tf.float32)\n",
    "\n",
    "# weight & bias\n",
    "W = tf.Variable(tf.random.normal([2,3]))\n",
    "b = tf.Variable(tf.random.normal([3]))\n",
    "\n",
    "# model, hypothesis\n",
    "logit = tf.matmul(X,W) +b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=T))\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-1).minimize(loss)\n",
    "\n",
    "# session 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 반복학습\n",
    "# 주의할 점: 학습데이터의 사이즈가 매우 크면 메모리에 데이터를 한번에 \n",
    "# 모두 loading할 수 없음, memory fault나면서 수행이 중지됨\n",
    "# => 해결법 : batch 처리를 해야함 -> 아래에서 해봄\n",
    "\n",
    "for step in range(10000):\n",
    "    _, loss_val = sess.run([train,loss],feed_dict={X:norm_train_x_data,\n",
    "                                                   T:onehot_train_t_data})\n",
    "    if step % 1000==0:\n",
    "        print('loss value : {}'.format(loss_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4780b9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 54\n",
      "loss value : 0.38820552825927734\n",
      "loss value : 0.025670865550637245\n",
      "loss value : 0.014760109595954418\n",
      "loss value : 0.010423058643937111\n",
      "loss value : 0.008026962168514729\n",
      "loss value : 0.006491709500551224\n",
      "loss value : 0.005420112982392311\n",
      "loss value : 0.0046287947334349155\n",
      "loss value : 0.004020511172711849\n",
      "loss value : 0.0035384460352361202\n"
     ]
    }
   ],
   "source": [
    "# batch처리하기\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2],dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,3],dtype=tf.float32)\n",
    "\n",
    "# weight & bias\n",
    "W = tf.Variable(tf.random.normal([2,3]))\n",
    "b = tf.Variable(tf.random.normal([3]))\n",
    "\n",
    "# model, hypothesis\n",
    "logit = tf.matmul(X,W) +b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=T))\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-1).minimize(loss)\n",
    "\n",
    "# session 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 반복학습\n",
    "# 주의할 점: 학습데이터의 사이즈가 매우 크면 메모리에 데이터를 한번에 \n",
    "# 모두 loading할 수 없음, memory fault나면서 수행이 중지됨\n",
    "# => 해결법 : batch 처리를 해야함 \n",
    "num_of_epoch = 1000 # 학습을 위한 전체 epoch 수\n",
    "num_of_batch = 10 # 한번에 학습할 데이터양\n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    total_batch = int(norm_train_x_data.shape[0] / num_of_batch)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_x = norm_train_x_data[i*num_of_batch:(i+1)*num_of_batch]\n",
    "        batch_y = onehot_train_t_data[i*num_of_batch:(i+1)*num_of_batch]                                \n",
    "        _, loss_val = sess.run([train,loss],feed_dict={X:batch_x,\n",
    "                                                   T:batch_y})\n",
    "    if step % 100==0:\n",
    "        print('loss value : {}'.format(loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2530186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 55\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\LG\\AppData\\Local\\Temp\\ipykernel_32288\\3424619669.py\", line 11, in <module>\n",
      "    T:onehot_test_t_data})\n",
      "NameError: name 'onehot_test_t_data' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\inspect.py\", line 1495, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\inspect.py\", line 1453, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\LG\\AppData\\Local\\Temp\\ipykernel_32288\\3424619669.py\", line 11, in <module>\n",
      "    T:onehot_test_t_data})\n",
      "NameError: name 'onehot_test_t_data' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\inspect.py\", line 1495, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\inspect.py\", line 1453, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\LG\\AppData\\Local\\Temp\\ipykernel_32288\\3424619669.py\", line 11, in <module>\n",
      "    T:onehot_test_t_data})\n",
      "NameError: name 'onehot_test_t_data' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\inspect.py\", line 1495, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\inspect.py\", line 1453, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\LG\\.conda\\envs\\machine_TF15\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "# 성능 평가\n",
    "# result = sess.run(H,feed_dict={X:scaler.transform(np.array([[187m81]]))})\n",
    "# print(np.argmax(result, axis=1))  # 가장 큰값의 인덱스를 알려줌\n",
    "# print(result)\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict,tf.argmax(T,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "result = sess.run(accuracy, feed_dict={X:norm_test_x_data,\n",
    "                                      T:onehot_test_t_data})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078e146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868bd7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973164ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd433bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ffa5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b38cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc41973d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae7fafd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
